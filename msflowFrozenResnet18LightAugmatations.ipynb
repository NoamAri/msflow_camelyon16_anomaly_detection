{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61e5b5-727e-4557-a72f-7892fbc53a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================\n",
    "# Dataset Loader\n",
    "# =============================\n",
    "class Camelyon16Dataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.image_paths, self.labels = [], []\n",
    "        self.transform = transform\n",
    "        if split == 'train':\n",
    "            folder = os.path.join(root_dir, 'train', 'good')\n",
    "            self.image_paths = [os.path.join(folder, f) for f in os.listdir(folder)]\n",
    "            self.labels = [0] * len(self.image_paths)\n",
    "        else:\n",
    "            g = os.path.join(root_dir, 'test', 'good')\n",
    "            b = os.path.join(root_dir, 'test', 'Ungood')\n",
    "            self.image_paths = [os.path.join(g, f) for f in os.listdir(g)] + [os.path.join(b, f) for f in os.listdir(b)]\n",
    "            self.labels = [0] * len(os.listdir(g)) + [1] * len(os.listdir(b))\n",
    "\n",
    "    def __len__(self): return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "# =============================\n",
    "# Augmentations\n",
    "# =============================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.05, 0.05, 0.05, 0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =============================\n",
    "# ResNet18 Frozen Extractor\n",
    "# =============================\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.stage1 = nn.Sequential(*list(model.children())[:5])  # ×¢×“ ×›×•×œ×œ layer1\n",
    "        self.stage2 = model.layer2\n",
    "        self.stage3 = model.layer3\n",
    "        self.stage4 = model.layer4\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        f1 = self.stage2(x)\n",
    "        f2 = self.stage3(f1)\n",
    "        f3 = self.stage4(f2)\n",
    "        return [f1, f2, f3]\n",
    "\n",
    "# =============================\n",
    "# MSFlow (RealNVP + Fusion)\n",
    "# =============================\n",
    "class ActNorm2d(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.bias = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
    "        self.logs = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean = x.mean([0, 2, 3], keepdim=True)\n",
    "            std = x.std([0, 2, 3], keepdim=True)\n",
    "            self.bias.data.copy_(-mean)\n",
    "            self.logs.data.copy_(torch.log(1 / (std + 1e-6)))\n",
    "            self.initialized = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.initialized: self.initialize(x)\n",
    "        return (x + self.bias) * torch.exp(self.logs)\n",
    "\n",
    "class RealNVPBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.norm = ActNorm2d(in_channels)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels // 2, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, in_channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_a, x_b = x.chunk(2, dim=1)\n",
    "        h = self.net(x_a)\n",
    "        s, t = h.chunk(2, dim=1)\n",
    "        s = torch.sigmoid(s + 2.0)\n",
    "        y_b = s * x_b + t\n",
    "        log_det = torch.sum(torch.log(s).reshape(x.size(0), -1), dim=1)\n",
    "        out = torch.cat([x_a, y_b], dim=1)\n",
    "        out = self.norm(out)\n",
    "        return out, log_det\n",
    "\n",
    "class MSFlow(nn.Module):\n",
    "    def __init__(self, channels_list):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList([\n",
    "            nn.Sequential(*[RealNVPBlock(c) for _ in range(3)]) for c in channels_list\n",
    "        ])\n",
    "\n",
    "    def forward(self, features):\n",
    "        scores = []\n",
    "        for i, flow in enumerate(self.flows):\n",
    "            x = features[i]\n",
    "            log_det = 0\n",
    "            for block in flow:\n",
    "                x, det = block(x)\n",
    "                log_det += det\n",
    "            log_prob = -0.5 * torch.sum(x ** 2, dim=[1, 2, 3]) + log_det\n",
    "            scores.append(log_prob)\n",
    "        return -sum(scores) / len(scores)\n",
    "\n",
    "# =============================\n",
    "# Train Loop\n",
    "# =============================\n",
    "def train_msflow():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    root_dir = r\"C:\\afeca academy\\×¡×™×ž×¡×˜×¨ ×‘\\advanced deep learning\\project Normalizing Flow\\MedlAnaomaly-Data\\Camelyon16\\Camelyon16\"\n",
    "    train_ds = Camelyon16Dataset(root_dir, 'train', transform)\n",
    "    val_ds = Camelyon16Dataset(root_dir, 'test', transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    extractor = ResNetFeatureExtractor().to(device)\n",
    "    flow = MSFlow([128, 256, 512]).to(device)  # ×‘×”×ª××ž×” ×œÖ¾ResNet18\n",
    "    optimizer = torch.optim.Adam(flow.parameters(), lr=1e-4)\n",
    "\n",
    "    best_auc = 0\n",
    "    for epoch in range(10):\n",
    "        flow.train()\n",
    "        total_loss = 0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            feats = extractor(x)\n",
    "            loss = flow(feats).mean()\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"âœ… Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
    "        evaluate(val_loader, extractor, flow, device)\n",
    "\n",
    "# =============================\n",
    "# Evaluation\n",
    "# =============================\n",
    "def evaluate(val_loader, extractor, flow, device):\n",
    "    flow.eval()\n",
    "    all_scores, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            feats = extractor(x)\n",
    "            scores = flow(feats)\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "            all_labels.extend([y.item()])\n",
    "    scores = np.array(all_scores)\n",
    "    scores_z = (scores - scores.mean()) / (scores.std() + 1e-8)\n",
    "    preds = (scores_z > 0).astype(int)\n",
    "    cm = confusion_matrix(all_labels, preds)\n",
    "    auc = roc_auc_score(all_labels, scores_z)\n",
    "    f1 = f1_score(all_labels, preds)\n",
    "    print(f\"ðŸ“Š Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"ðŸ“ˆ ROC AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bcb7b6-c752-404e-b919-dc4ac66105ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 Avg Loss: 23052.1996\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[753 367]\n",
      " [336 777]]\n",
      "ðŸ“ˆ ROC AUC: 0.7266 | F1: 0.6885\n",
      "âœ… Epoch 2 Avg Loss: 11987.0105\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[767 353]\n",
      " [335 778]]\n",
      "ðŸ“ˆ ROC AUC: 0.7299 | F1: 0.6934\n",
      "âœ… Epoch 3 Avg Loss: 7149.5825\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[762 358]\n",
      " [324 789]]\n",
      "ðŸ“ˆ ROC AUC: 0.7329 | F1: 0.6982\n",
      "âœ… Epoch 4 Avg Loss: 4449.9575\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[773 347]\n",
      " [340 773]]\n",
      "ðŸ“ˆ ROC AUC: 0.7312 | F1: 0.6923\n",
      "âœ… Epoch 5 Avg Loss: 2829.3960\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[778 342]\n",
      " [344 769]]\n",
      "ðŸ“ˆ ROC AUC: 0.7306 | F1: 0.6915\n",
      "âœ… Epoch 6 Avg Loss: 1816.0876\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[768 352]\n",
      " [351 762]]\n",
      "ðŸ“ˆ ROC AUC: 0.7239 | F1: 0.6843\n",
      "âœ… Epoch 7 Avg Loss: 1172.5379\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[775 345]\n",
      " [345 768]]\n",
      "ðŸ“ˆ ROC AUC: 0.7249 | F1: 0.6900\n",
      "âœ… Epoch 8 Avg Loss: 759.0340\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[773 347]\n",
      " [347 766]]\n",
      "ðŸ“ˆ ROC AUC: 0.7302 | F1: 0.6882\n",
      "âœ… Epoch 9 Avg Loss: 492.1548\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[763 357]\n",
      " [361 752]]\n",
      "ðŸ“ˆ ROC AUC: 0.7233 | F1: 0.6769\n",
      "âœ… Epoch 10 Avg Loss: 319.6370\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[772 348]\n",
      " [349 764]]\n",
      "ðŸ“ˆ ROC AUC: 0.7250 | F1: 0.6867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_msflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743cf2d7-6422-4c39-94bb-b5929eaeb191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
